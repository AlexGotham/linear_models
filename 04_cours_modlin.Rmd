
# ANOVA à deux facteurs sans répétition

Ce chapitre est largement inspiré du cours "Analyse de variance à 2 facteurs" disponible en mars 2020 sur http://math.agrocampus-ouest.fr.


**Données**

```{r results="verbatim"}
varfung = data.frame(
  land=1:6,
  variety=c("A","A","B","B","C","C"),
  fungicide=c("Y","Z","Y","Z","Y","Z"),
  yield=c(2,2,1,5,3,5)
)
varfung$variety = as.factor(varfung$variety)
varfung$fungicide = as.factor(varfung$fungicide)
varfung
# m = lm (yield~variety+fungicide, d)
# summary(m)
```

Nous nous plaçons ici dans le cadre d’un plan 

  - complet (toutes les combinaisons de facteurs sont présentent) 
  - équirépété (même nombre de répétition pour chaque combinaison). 

Ce type de plan à de bonnes propriétés : 
 
  - numériques / d’optimalité
  - facilité d’interprétation

L’ANOVA à 2 facteurs fonctionne aussi dans le cadre de plan qui ne sont ni complets ni équirépétés, les calculs sont plus compliqués et l’interprétation moins évidentes.

**Notations**

  - $y_{ij}$ le rendement de la variété $i$ avec le fongicide $j$.
  - $\overline y_{i.}$ la moyenne des rendements pour la variété $i$ 
  - $\overline y_{.j}$ la moyenne des rendements pour le fongicide $j$ 
  - $\overline y_{..}$ la moyenne des rendements

**Travaux pratiques** : calculez $\overline y_{i.}$, $\overline y_{.j}$ et $\overline y$.

```{r results="verbatim"}
d = varfung
df = as.data.frame(matrix(d$yield,nrow=3, byrow=TRUE))
colnames(df) = unique(d$fungicide)
rownames(df) = unique(d$variety)
df

df2 = df
yi = apply(df2, 1, mean)
yj = apply(df2, 2, mean)
y = mean(yi)
df2$'yi.' = yi
df2 = rbind(df2, c(yj, y))
rownames(df2) = c(levels(d$variety), "y.j")
df2
```

**Problématique**

  - Est-ce qu’il y a un effet de la variété sur le rendement ?
  - Est-ce qu’il y a un effet du fongicide sur le rendement ?


## Présentation du modèles


$$Y_{ij} = \mu + \alpha_i + \beta_j + \epsilon_{ij}$$

avec  : 

  - $Y_{ij}$ le rendement de la variété $i$ avec le fongicide $j$ 
  - $\mu$ un rendement basal
  - $\alpha_i$ l’effet de la variété $i$
  - $\beta_j$ l’effet du fongicide $j$
  - $\epsilon_{ij}$ un résidu aléatoire (variabilité biologique)
  
**Hypothèse sur les résidus**
  
  - normalité (avec cette hypothèse les lois sont exactes, sans cette hypothèse les approximations sont généralement bonnes,  le modèle est robuste à cette hypothèse)
  - homoscédasticité (important)
  - indépendance des résidus (important)
  
**Contrainte sur les paramètres**
  
  - $\sum \alpha_i = 0$
  - $\sum \beta_j = 0$
  
Nous avons donc $I + J + 1$ paramètres dont $I + J - 1$ paramètres indépendants.


## Estimation des paramètres

$$ y_{ij} = \widehat \mu + \widehat \alpha_i + \widehat \beta_j + e_{ij}$$

avec : 

  - $argmin(\sum (e_{ij})^2)$
  - $\sum \widehat \alpha_i = 0$
  - $\sum \widehat \beta_j = 0$

Dans le cadre du plan complet equirépété : 

  - $\widehat \mu = \overline y_{..}$
  - $\widehat \alpha_i = \overline y_{i.} - \overline y_{..}$
  - $\widehat \beta_j = \overline y_{.j} - \overline y_{..}$


**Travaux pratiques** : calculez $\widehat \mu$, $\widehat \alpha_i$, et $\widehat \beta_j$

```{r results="verbatim"}
d = varfung
df = as.data.frame(matrix(d$yield,nrow=3, byrow=TRUE))
colnames(df) = unique(d$fungicide)
rownames(df) = unique(d$variety)

df2 = df
yi = apply(df2, 1, mean)
yj = apply(df2, 2, mean)
y = mean(yi)
df2$'yi.' = yi
df2 = rbind(df2, c(yj, y))
rownames(df2) = c(levels(d$variety), "y.j")
df2

df3 = df
ai = yi - y
bj = yj - y
df3$'ai' = ai
df3 = rbind(df3, c(bj, mean(bj)))
rownames(df3) = c(levels(d$variety), "bj")
df3

```


## Qualité du modèle

### Etude des résidus

la valeur prédite vaut : 

$$\widehat y_{ij} = \widehat \mu + \widehat \alpha_i + \widehat \beta_j$$


Ainsi : 

\begin{eqnarray}
e_{ij} &=& y_{ij} - \widehat y_{ij}   \\
       &=& y_{ij} - (\widehat \mu + \widehat \alpha_i + \widehat \beta_j) \\
       &=& y_{ij} - (\overline y_{..} + (\overline y_{i.} - \overline y_{..}) + (\overline y_{.j} - \overline y_{..})) \\
       &=& y_{ij} - \overline y_{i.} - \overline y_{.j} + \overline y_{..}
\end{eqnarray}



Avec (propriété) : 

$$ \forall j \sum_i e_{ij} = 0,  \forall i \sum_j e_{ij} = 0$$

**Travaux pratiques** : calculez les $e_{ij}$.

```{r results="verbatim"}
d = varfung
df = as.data.frame(matrix(d$yield,nrow=3, byrow=TRUE))
colnames(df) = unique(d$fungicide)
rownames(df) = unique(d$variety)

df2 = df
yi = apply(df2, 1, mean)
yj = apply(df2, 2, mean)
y = mean(yi)
df2$'yi.' = yi
df2 = rbind(df2, c(yj, y))
rownames(df2) = c(levels(d$variety), "y.j")

df3 = df
ai = yi - y
bj = yj - y
df3$'ai' = ai
df3 = rbind(df3, c(bj, mean(bj)))
rownames(df3) = c(levels(d$variety), "bj")
df3

df4 = t(t(df - ai) - bj) - y 
df4 = cbind(df4, apply(df4, 1, sum))
df4 = rbind(df4, apply(df4, 2, sum))
df4
```

### Décomposition de la variance

$$y_{ij} - \overline y = (\overline y_{i.} - \overline y) + (\overline y_{.j} - \overline y) + (y_{ij} - \overline y_{i.} - \overline y_{.j} + \overline y)$$


Dans le cadre du plan équirépétés : 

\begin{eqnarray}

\sum_i \sum_j (y_{ij} - \overline y)^2 &=& \sum_i J (\overline y_{i.} - \overline y)^2 &+& \sum_j I (\overline y_{.j} - \overline y)^2 &+& \sum_i \sum_j (y_{ij} - \widehat y_{ij})^2 \\
                                       &=&  J \sum_i \widehat \alpha_i^2  &+& I \sum_j \widehat \beta_j^2 &+& \sum_i \sum_j e_ij^2 \\
                              SC_{tot} &=&  SC_{F_1}                       &+&  SC_{F_2}                    &+& SC_{res} 
\end{eqnarray}


**Indicateur d’adéquation du modèle** 
 
$$R^2 =  \frac{SC_{tot} - SC_{res}}{SC_{tot}}$$

**Travaux pratiques** : calculez $SC_{F_1}$, $SC_{F_2}$, $SC_{res}$, $SC_{tot}$ et $R^2$.


```{r results="verbatim"}
d = varfung
df = as.data.frame(matrix(d$yield,nrow=3, byrow=TRUE))
colnames(df) = unique(d$fungicide)
rownames(df) = unique(d$variety)

df2 = df
yi = apply(df2, 1, mean)
yj = apply(df2, 2, mean)
y = mean(yi)
df2$'yi.' = yi
df2 = rbind(df2, c(yj, y))
rownames(df2) = c(levels(d$variety), "y.j")

df3 = df
ai = yi - y
bj = yj - y
df3$'ai' = ai
df3 = rbind(df3, c(bj, mean(bj)))
rownames(df3) = c(levels(d$variety), "bj")
df3

df4 = t(t(df - ai) - bj) - y 
df4 = cbind(df4, apply(df4, 1, sum))
df4 = rbind(df4, apply(df4, 2, sum))
df4

c(
  SC_F1 = ncol(df) * sum(ai^2), 
  SC_F2 = nrow(df) * sum(bj^2), 
  SC_res = sum(df4^2)         , 
  SC_tot = sum((df - y)^2)
)
```


## Tests statistiques

### Test de Fisher

Test global de l’effet **d’un** facteur.

  - $H_0 : \alpha_i = 0, \forall i$
  - $H_1 : \exists i, \alpha_i \neq 0$

On compare la variabilité des moyennes $\overline y_{i.}$ et la variabilité résiduelle $\sigma^2$ en considèrant le rapport suivant : 

$$ F_{obs} = \frac{\frac{SC_{F_1}}{I-1}}{\frac{SC_{res}}{n-I-J+1}} = \frac{cm_{F_1}}{cm_{res}}$$

Si les conditions d’applications sont satisfaites et sous $H_0$ alors $F_{obs}$ est une réalisation d’une variable aléatoire $F$ qui suit une loi de Fisher à $I-1$ degrés de liberté au numérateur et $n-I-J+1$ degrés de liberté au dénominateur. Cette loi est notée  $\mathcal{F}_{I-1,n-I-J+1}$.



| Source de variation   | sc        | ddl        |  cm  | $F_{obs}$
| :--------------------:| :-------: | :--:       | :--: | ---:
| Due au facteur 1      | $sc_{F_1}$| $I-1$      | $cm_{F_1}=\frac{sc_{F_1}}{I-1}$    | $\frac{cm_{F_1}}{cm_{res}}$
| Due au facteur 2      | $sc_{F_2}$| $J-1$      | $cm_{F_2}=\frac{sc_{F_2}}{J-1}$    | $\frac{cm_{F_2}}{cm_{res}}$
| Résiduelle            | $sc_{res}$| $n-I-J+1$  | $cm_{res}=\frac{sc_{res}}{n-I-J+1}$ 
| Totale                | $sc_{tot}$| $n-1$ 


```{r results="verbatim"}
options(contrasts=c("contr.sum", "contr.poly")) # indique que, dans le cas équilibré, les estimations des effets alpha de chaque groupe doivent être de somme nulle
m = lm (yield~variety+fungicide, varfung)
print(anova(m))

ddl_f1  = 2
ddl_f2  = 1
ddl_res = 2
sc_f1  = 4
sc_f2  = 6
sc_res = 4
cm_f1  =  sc_f1 / ddl_f1
cm_f2  =  sc_f2 / ddl_f2
cm_res = sc_res / ddl_res
f_obs_f1 = cm_f1 / cm_res
f_obs_f2 = cm_f2 / cm_res

layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
x = seq(0,3*f_obs_f1, length.out=100)
plot(x,df(x, ddl_f1, ddl_res), type="l", main=paste0("F_", ddl_f1, "_", ddl_res, ", Fobs_F1=", f_obs_f1, ", P(>F)=", signif(1-pf(f_obs_f1,ddl_f1, ddl_res),3)), ylab=paste0("df(x, ", ddl_f1, ", ", ddl_res, ")"))
polygon(c(f_obs_f1,f_obs_f1, 10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=f_obs_f1, col=2)

x = seq(0,3*f_obs_f2, length.out=100)
plot(x,df(x, ddl_f2, ddl_res), type="l", main=paste0("F_", ddl_f2, "_", ddl_res, ", Fobs_F2=", f_obs_f2, ", P(>F)=", signif(1-pf(f_obs_f2,ddl_f2, ddl_res),3)), ylab=paste0("df(x, ", ddl_f2, ", ", ddl_res, ")"))
polygon(c(f_obs_f2,f_obs_f2,  10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=f_obs_f2, col=2)
```



### Test de Student

Test de la significativité d’un **coefficient**. 

- $H_0 : \alpha_i = 0$
- $H_1 : \alpha_i \neq 0$

$\widehat \alpha_i$ suit une loi normale de moyenne $\alpha_i$ et variance $\sigma_{\widehat \alpha_i}^2$ inconnue.

La variance est estimée par $\widehat \sigma_{\widehat \alpha_i}^2 = \frac{I-1}{I }\frac{CM_{res}}{J}$ et donc la statistique de test est :

$$t_{obs} = \frac{\widehat \alpha_i}{\widehat \sigma_{\widehat \alpha_i}}$$

Si les conditions d’applications sont satisfaites et sous $H_0$ alors la valeur absolue de $t_{obs}$ est une réalisation d’une variable aléatoire $t$ qui suit une loi de Student à $n-I-J+1$ degrés de liberté. Cette loi est notée  $\mathcal{t}_{n-I-J+1}$.


```{r results="verbatim"}
m = lm (yield~variety+fungicide, varfung)
print(summary(m))

n = 6
I = 3
J = 2
a1 = -1
a2 = 0
a3 = 1
b1 = -1
b2 = 1
s_ai = (I-1)/(I*J) * cm_res
s_ai
s_bj = (J-1)/(J*I) * cm_res
s_bj
t_obs_a1 = abs(a1 / sqrt(s_ai))
t_obs_a2 = abs(a2 / sqrt(s_ai))
t_obs_a3 = abs(a3 / sqrt(s_ai))
t_obs_b1 = abs(b1 / sqrt(s_bj))
t_obs_b2 = abs(b2 / sqrt(s_bj))

ddl = n-I-J+1

layout(matrix(1:6, 2, byrow=TRUE), respect=TRUE)
x = seq(-4, 4, length.out=100)
pv = min(1,1-pt(t_obs_a1,ddl) + pt(-t_obs_a1,ddl))
plot(x,dt(x, ddl), type="l", main=paste0("t_", ddl, ", |tobs_a1|=", signif(t_obs_a1, 3), ", P(>t)=", signif(pv, 3)), ylab=paste0("dt(x, ", ddl, ")"))
polygon(c(t_obs_a1,t_obs_a1, 10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
polygon(c(-t_obs_a1,-t_obs_a1, -10, -10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=c(-1, 1)*t_obs_a1, col=2)

x = seq(-4, 4, length.out=100)
pv = min(1, 1-pt(t_obs_a2,ddl) + pt(-t_obs_a2,ddl))
plot(x,dt(x, ddl), type="l", main=paste0("t_", ddl, ", |tobs_a2|=", signif(t_obs_a2, 3), ", P(>t)=", signif(pv, 3)), ylab=paste0("dt(x, ", ddl, ")"))
polygon(c(t_obs_a2,t_obs_a2, 10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
polygon(c(-t_obs_a2,-t_obs_a2, -10, -10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=c(-1, 1)*t_obs_a2, col=2)

x = seq(-4, 4, length.out=100)
pv = min(1, 1-pt(t_obs_a3,ddl) + pt(-t_obs_a3,ddl))
plot(x,dt(x, ddl), type="l", main=paste0("t_", ddl, ", |tobs_a3|=", signif(t_obs_a3, 3), ", P(>t)=", signif(pv, 3)), ylab=paste0("dt(x, ", ddl, ")"))
polygon(c(t_obs_a3,t_obs_a3, 10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
polygon(c(-t_obs_a3,-t_obs_a3, -10, -10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=c(-1, 1)*t_obs_a3, col=2)

x = seq(-4, 4, length.out=100)
pv = min(1, 1-pt(t_obs_b1,ddl) + pt(-t_obs_b1,ddl))
plot(x,dt(x, ddl), type="l", main=paste0("t_", ddl, ", |tobs_b1|=", signif(t_obs_b1, 3), ", P(>t)=", signif(pv, 3)), ylab=paste0("dt(x, ", ddl, ")"))
polygon(c(t_obs_b1,t_obs_b1, 10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
polygon(c(-t_obs_b1,-t_obs_b1, -10, -10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=c(-1, 1)*t_obs_b1, col=2)

x = seq(-4, 4, length.out=100)
pv = min(1, 1-pt(t_obs_b2,ddl) + pt(-t_obs_b2,ddl))
plot(x,dt(x, ddl), type="l", main=paste0("t_", ddl, ", |tobs_b2|=", signif(t_obs_b2, 3), ", P(>t)=", signif(pv, 3)), ylab=paste0("dt(x, ", ddl, ")"))
polygon(c(t_obs_b2,t_obs_b2, 10, 10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
polygon(c(-t_obs_b2,-t_obs_b2, -10, -10), c(-10, 10, 10, -10), col=adjustcolor("grey", alpha.f=0.5))
abline(v=c(-1, 1)*t_obs_b2, col=2)
```



## Exercices

Etudier les jeux de données suivants : 


1. Ecriture analytique du modèle ;
2. Formulation des hypothèses $\mathcal{H}_0$ et $\mathcal{H}_1$ ;
3. Statistique de test utilisée et **conditions d’application** ; 
4. Valeur de la statistique de test ; 
5. P-valeur associée ; 
6. Conclusion du test.


```{r, eval=TRUE, echo=TRUE, results="verbatim"}
# Note sur les contrasts
# https://www.dummies.com/programming/r/how-to-set-the-contrasts-for-your-data-with-r/
# X = levels(rats$poison)
# contr.treatment(X)
# contr.sum(X)
options(contrasts=c("contr.sum", "contr.poly")) # indique que, dans le cas équilibré, les estimations des effets alpha de chaque groupe doivent être de somme nulle

d = ISwR::lung
head(d)
dim(d)
table(d$method, d$subject)
layout(matrix(1:2,1), respect=TRUE)
plot(volume~method+subject, d)

```
```{r eval=FALSE}
# 1. vol_ij = vol_basal + meth_i + sub_j + e_ij
# 2.0 H_0: meth_i = 0 pour tout i.
#     H_1: il existe i tel que meth_i != 0 
# 2.1 H_0: meth_a = 0
#     H_1: meth_a != 0 
# 2.2 H_0: meth_b = 0
#     H_1: meth_b != 0 
# 2.3 H_0: meth_c = 0
#     H_1: meth_c != 0 

# 3. res. gaussiens : 
d = ISwR::lung
m = lm(volume~method+subject,d)
shapiro.test(m$residuals) # distrib. normale pour les res.


# 4.0 Fisher
anova(m)
layout(matrix(1:2,1), respect=TRUE)
plot(TukeyHSD(aov(volume~method+subject,d), conf.level=0.95), las = 2)

# 4.1 Student
summary(m)
meth_A = m$coefficient[2]
meth_A
meth_C = -sum(m$coefficient[2:3])
meth_C

err_meth = summary(m)$coefficients[2,2]
err_meth

F_obsA = meth_A / err_meth
F_obsA
F_obsC = meth_C / err_meth
F_obsC

pval_methA = 2*(1 - pt(abs(F_obsA),10))
pval_methA
pval_methC = 2*(1 - pt(abs(F_obsC),10))
pval_methC


# df = nb_obs - nb_param_libre
# df = nb_obs - (nb_param - nb_contraintes)
18 - ((1 + 6 + 3) - 1 - 1)
```


````{r, eval=TRUE, echo=TRUE, results="verbatim"}
library(lsmeans)
d = auto.noise
head(d)
dim(d)
table(d$size, d$type)
layout(matrix(1:2,1), respect=TRUE)
plot(noise~size+type, d)

```

```{r eval=FALSE}
d = auto.noise
m = lm(noise~size+type, d)

shapiro.test(m$residuals) # Attention !!
bartlett.test(noise~I(d$size:d$type), d) # Attention !!
# d$comb = factor(paste(d$size,d$type, sep="_"))
# bartlett.test(noise~d$comb, d)
# d$comb = factor(paste(d$size,d$type, sep="_"))
# bartlett.test(noise~d$comb, d)
# m = lm(noise~comb, d)
# shapiro.test(m$residuals)
#
# m = lm(noise~size+type+side, d)
# shapiro.test(m$residuals)

anova(m)

```








```{r, eval=TRUE, echo=TRUE, results="verbatim"}
d = faraway::rats
head(d)
dim(d)
table(d$poison, d$treat)
layout(matrix(1:2,1), respect=TRUE)
plot(time~poison+treat, d)

```
```{r, eval=TRUE, echo=TRUE, results="verbatim"}
Penicillin = lme4::Penicillin
head(Penicillin)
dim(Penicillin)
table(Penicillin$plate, Penicillin$sample)

```
```{r, eval=TRUE, echo=TRUE, results="verbatim"}
cake = lme4::cake
head(cake)
dim(cake)
table(cake$temperature, cake$recipe)
```










```{r, eval=FALSE}
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
boxplot(time~poison+treat,rats, las=2)
boxplot(log(time)~poison+treat,rats, las=2)
# homosedacticity
bartlett.test(time~I(poison:treat), rats)
bartlett.test(log(time)~I(poison:treat), rats)

# normality
rats = faraway::rats
m = lm(log(time)~poison+treat,rats)
shapiro.test(m$residuals)

# Fisher
anova(m)
# Student
summary(m)

# TukeyHSD
layout(matrix(1:3, 1, byrow=TRUE), respect=TRUE)
boxplot(log(time)~poison+treat,rats, las=2)
m2 = aov(log(time)~poison+treat,rats)
plot(TukeyHSD(m2, conf.level=0.95))

```

```{r, eval=FALSE}
boxplot(diameter~plate+sample,Penicillin, las=2)
m = lm(diameter~plate+sample,Penicillin)
shapiro.test(m$residuals)
anova(m)
summary(m)
```

```{r, eval=FALSE}
m = lm (yield~variety+fungicide, varfung)
anova(m)
m = lm (yield~fungicide+variety, varfung)
anova(m)

d = state_us
m = lm(Life.Exp ~ Murder + HS.Grad, d)
anova(m)
m = lm(Life.Exp ~ HS.Grad + Murder, d)
anova(m)






Y~A+B



# equirépété
df = data.frame(
  A=c(0, 0, 1, 1, 2, 2, 0, 1, 2),
  B=c(0, 1, 0, 1, 0, 1, 2, 2, 2)
)
table(df$A, df$B)
plot(df$A, df$B)
df

df$Y = 6*df$A + 3*df$B + rnorm(nrow(df))
df 

m = lm(Y~A+B, df)
anova(m)
m = lm(Y~B+A, df)
anova(m)


# factors
df$A = as.factor(df$A)
df$B = as.factor(df$B)


m = lm(Y~A+B, df)
anova(m)
m = lm(Y~B+A, df)
anova(m)



# pas equirépété (correlation entre A et B)
df = data.frame(
  A=c(0, 0, 1, 1, 2, 1, 2),
  B=c(0, 1, 0, 1, 1, 2, 2)
)
table(df$A, df$B)
plot(df$A, df$B, col=2)
df

df$Y = 6*df$A + 3*df$B + rnorm(nrow(df))
df 

m = lm(Y~A+B, df)
anova(m)
m = lm(Y~B+A, df)
anova(m)












# pas equilibré equirépété (correlation entre A et B)
df = data.frame(
  A=c(0, 1, 2, 0, 2),
  B=c(0, 1, 0, 2, 2)
)
table(df$A, df$B)
plot(df$A, df$B, col=2, pch=16, cex=3)
df

df$Y = 6*df$A + 3*df$B + rnorm(nrow(df))
df 

m = lm(Y~A+B, df)
anova(m)
m = lm(Y~B+A, df)
anova(m)





replicat
df = rbind(df, df, df, df, df, df, df, df)
set.seed(1)
df$Y = 6*df$A+rnorm(nrow(df))+3*df$B*rnorm(nrow(df))

# factors
df$A = as.factor(df$A)
df$B = as.factor(df$B)


m = lm(Y~A+B, df)
anova(m)
m = lm(Y~B+A, df)
anova(m)
```








