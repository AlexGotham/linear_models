 
# ANOVA à un facteur

Dans le cadre de l’analyse de la variance (**ANOVA**) on cherche une relation entre la variable observée $Y$ quantitative et la variable explicative $X$ qualitative, appellée aussi facteur. 

$$Y \sim X$$

Comme pour la regression linéaire, l’ANOVA est à la fois:

  * un **modèle** (linéaire) fondé sur la décomposition de la variance 
  * un **test** statistique permettant de comparer les moyennes d’une variable aléatoire *indépendante*, *gaussienne* et *homogène en variance*.

Ex : le poids moyen de différents groupes d’individus.

L’analyse de la variance est une procédure largement utilisée dans les métiers qui font appel aux statistiques et à ’analyse de données.
  

## Présentation du modèle


Y est la variable aléatoire expliquée (modélisée) par  la variables explicatives $X$. 

Le modèle s’écrit :

$$Y = \mu + I_X \beta + \epsilon$$

avec : 

  - $Y$ un vecteur de taille $n$ (le nombre d’obeservations) correspondant aux valeurs de la variable aléatoire 
  - $\mu$ la moyenne des observations.  
  - $\epsilon$ un vecteur de taille $n$ correspondant aux valeurs des résidus. 
  - $\beta$ un vesteur de  $p$ (le nombre de niveaux du facteur X) correspondant à la moyenne des observation pour chaque niveau du facteur moins la moyenne générale.
  - $I_X$ la *matrice d’incidence* (tableua disjonctif ?) de taille $n$ x $p$, ne comportant que des 0 et des 1 et permettant d’associer chaque observation à son niveau de facteur $X$.   

**Exemple *InsectSprays* **

Les données *InsectSprays* décrivent 72 parcelles agricoles par le nombre d’insectes qu’elles contiennent (*count*) et le type d’insecticide auquel elles ont été exposées (*spray*).
On pourra tenter d’expliquer le nombre d’insectes (Y) en fonction du type de insecticide (X), ou s’intérroger sur l’effet du type de insecticide utilisé (X) sur le nombre d’insectes observé (Y).

```{r results="verbatim", echo=TRUE}
data("InsectSprays")
head(InsectSprays)
dim(InsectSprays)
table(InsectSprays$spray)
```




```{r}
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
p = plot(InsectSprays$spray, InsectSprays$count, main="count~spray", xlab="spray", ylab="count", border="grey")
points(jitter(as.numeric(InsectSprays$spray)), InsectSprays$count)


y_i = sapply(levels(InsectSprays$spray), function(s) {
 mean(InsectSprays[InsectSprays$spray==s,]$count)
})
sp = jitter(as.numeric(InsectSprays$spray))
plot(sp, InsectSprays$count, main="count~spray", las=2, type="p", xaxt="n", xlab="spray", ylab="count")
suppressWarnings(arrows(sp, InsectSprays$count, sp, rep(y_i,each=12), col=adjustcolor(4, alpha.f=0.5), length=0.05))
points(y_i, pch=5, col=2)
suppressWarnings(arrows(1:6, mean(y_i), 1:6, y_i, col=adjustcolor(2, alpha.f=0.9), length=0.05))
abline(h=mean(y_i), lty=2)

axis(1, 1:length(levels(InsectSprays$spray)), labels=levels(InsectSprays$spray))
legend("top", c("Y_i", "beta_i", "epsilon_i", "mu"), pch=c(1,5,5,NA), col=c(1,2,4,1), lty=c(0,0,0,2), border=0)
```

Le modèle $Y = \mu + I_X \beta + \epsilon$ devient pour chaque observation i, $i \in \{1, ..., n\}$ :

$$Y_i = \mu + \beta_i + \epsilon_i$$

avec $\beta_i$ la moyenne des observations pour les individus dont le niveau du facteur X est le même que le niveau du facteur X de l’individu $i$.

Notes : 

  - $\beta_i$ prend ses valeurs dans $\{ \beta_A, \beta_B, \beta_C, \beta_D, \beta_E, \beta_F \}$, les moyennes des observations pour les individus des groupes A, B, C, D, E et F
  - si les groupes sont équilibrés : $\beta_A + \beta_B + \beta_C + \beta_D + \beta_E + \beta_F = 0$ 




























---

## Décomposition de la variance

**Notations**

Les observations sont notées $Y_{jk}$ avec :

- $j$ identifie le type d’insecticide, $j \in J = \{ A, B, C, D, E, F \}$.
- $k$ identifie la *k*-éme observation (réplicat) pour chaque type d’insecticide avec $k \in K = \{1,...,12\}$.

Ici, les groupes sont de même taille, nous disons que l’expérience est équilibrée. Au delà du fait que cela simplifie la notation, cela confère de bonnes propriétés utilisées pour décomposer la variance.

La moyenne observée du groupe $j$ s’écrit : 
$$\overline Y_j = \frac{1}{|K|}\sum_{k \in K}Y_{jk}$$

La variance observée du groupe $j$ s’écrit : 
$$s_j^2(Y) = \frac{1}{|K|}\sum_{k \in K}(Y_{jk} -\overline Y_j)^2$$


*Remarque* : Cette dernière formule exprime la variance non corrigée. Très souvent, dans les ouvrages ou les logiciels, c’est la variance corrigée qui est utilisée : au lieu d’être divisée par $|K|$, la somme est divisée par $|K| − 1$.


**Propriétés fondamentales**

La décomposition est fondée sur deux propriétés des moyennes et des variances.

(1) La moyenne de toutes les observations est la moyenne des moyennes de chaque échantillon : 

$$\overline{Y} 
  = \frac{1}{n} \sum_{j \in J} \sum_{k\in K} Y_{jk}
  = \frac{1}{|J| . |K|} \sum_{j \in J} \sum_{k\in K} Y_{jk}
  = \frac{1}{|J|} \sum_{j \in J} \frac{1}{|K|} \sum_{k\in K} Y_{jk}
  = \frac{1}{|J|} \sum_{j \in J} \overline{Y_j} $$


(2) La variance de toutes les observations est la somme de la variance des moyennes de chaque groupe et des variances de chaque observation autour de la moyenne de son groupe :

$$s^2(Y) 
  = \frac{1}{n} \sum_{j \in J} \sum_{k \in K} (Y_{jk} - \overline{Y})^2 
  = \frac{1}{n} \sum_{j \in J} \sum_{k \in K} (Y_{jk} - \overline Y_j)^2 + (\overline Y_j - \overline{Y})^2 
  = \frac{1}{|J|} \sum_{j \in J} (\overline{Y_j} - \overline{Y})^2 + \frac{1}{|J|} \sum_{j \in J} s_j^2(Y) $$

On conserve la proriété vu dans la regression linéaire :
 
$$ SC_{tot} = SC_{F} + SC_{res}$$ 

Avec $SC_{tot}$ la somme des carrés totale,  $SC_{F}$ la somme des carrés des facteurs et  $SC_{res}$ la somme des carrés des résidus.


Le coefficient de determination $R^2$ mesure du pourcentage de la variance expliquée par le modèle :

$$ R^2 = \frac{SC_{F}}{SC_{tot}}$$


```{r}
y_i = sapply(levels(InsectSprays$spray), function(s) {
 mean(InsectSprays[InsectSprays$spray==s,]$count)
})
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
sp = jitter(as.numeric(InsectSprays$spray))
plot(sp, InsectSprays$count, main="count~spray", las=2, type="p", xaxt="n", xlab="spray", ylab="count")
suppressWarnings(arrows(sp, InsectSprays$count, sp, rep(y_i,each=12), col=adjustcolor(4, alpha.f=0.5), length=0.05))
points(y_i, pch=5, col=2)
suppressWarnings(arrows(1:6, mean(y_i), 1:6, y_i, col=adjustcolor(2, alpha.f=0.9), length=0.05))
abline(h=mean(y_i), lty=2)

axis(1, 1:length(levels(InsectSprays$spray)), labels=levels(InsectSprays$spray))
legend("top", c("Y_ij", "SC_F", "SC_res"), pch=c(1,5,5), col=c(1,2,4))
```






**Travaux pratiques**

  - Reprendre le travaille effectué sur le jeu de données *CO2*.
  - Considérer la concentration en CO2 comme un facteur
  - Evaluer la part de variance expliquée par ce nouveau modèle (R^2)
  - Commenter


```{r echo=TRUE, results="verbatim"}
data(CO2)
head(CO2)
CO2_quebec = CO2[CO2$Type=="Quebec" & CO2$Treatment=="chilled", ]
CO2_quebec$conc_fact = as.factor(CO2_quebec$conc)
m1 = lm(uptake~conc, CO2_quebec)
layout(matrix(1:2, 1), respect=TRUE)
plot(
  CO2_quebec$conc, 
  CO2_quebec$uptake, 
  xlab="cooc", ylab="uptake", main=paste0("uptake~cooc R^2=", signif(summary(m1)$r.squared,3))
)
abline(m1, col=2)
plot(
  CO2_quebec$conc_fact, 
  CO2_quebec$uptake, 
  xlab="log(cooc)", ylab="uptake", main=paste0("uptake~cooc")
)
```


```{r eval=FALSE}
# README RStudio config, uncheck: # preferences > R Markdown > show output inline for... 
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
plot(
  CO2_quebec$conc, 
  CO2_quebec$uptake, 
  xlab="cooc", ylab="uptake", main=paste0("uptake~cooc R^2=", signif(summary(m1)$r.squared,3))
)
m = lm(uptake ~ conc, CO2_quebec)
abline(a=m$coefficients[[1]], b=m$coefficients[[2]], col=2) # /!\ y = b.x + a
arrows(CO2_quebec$conc, CO2_quebec$uptake, CO2_quebec$conc, CO2_quebec$uptake-m$residuals, col=adjustcolor(4, alpha.f=0.5), length=0.1)
legend("bottomright",c("regression line", "residuals"), col=c(2,4), lty=1, cex=.8)

m2 = lm(uptake ~ conc_fact, CO2_quebec)
summary(m2)$r.squared
p = plot(CO2_quebec$conc_fact, CO2_quebec$uptake, las=2, main=paste0("uptake~conc_fact R^2=", signif(summary(m2)$r.squared,3)))
conc_fact = jitter(as.numeric(CO2_quebec$conc_fact))
arrows(conc_fact, CO2_quebec$uptake, conc_fact, CO2_quebec$uptake-m2$residuals, col=adjustcolor(4, alpha.f=0.5), length=0.1)
legend("bottomright","residuals", col=4, lty=1, cex=.8)

```
  
---
































## Test de l'ANOVA à 1 facteur (*one way ANOVA*)

Sous certaines conditions d’aplications : 

- Indépendance des observations
- Homoscedasticité entre les groupes
- Normalité des résidus,

l’ANOVA est un test de comparaison des moyennes des facteurs : 

- hypothèse nulle $H_0, \mu_1 =\mu_2 =···=\mu_I$
- hypothèse alternative $H_1, \text{les moyennes } \mu_i \text{ ne sont pas toutes égales.}$

**Intuition du test** Si l’hypothèse nulle $H_0$ est vraie alors la quantité $SC_F$ (rouge) doit être petite par rapport à la quantité $SC_{res}$ (bleu).
Par contre, si l’hypothèse alternative $H_1$ est vraie alors la quantité $SC_F$ doit être grande par rapport à la quantité $SC_{res}$.


```{r}
y_i = sapply(levels(InsectSprays$spray), function(s) {
 mean(InsectSprays[InsectSprays$spray==s,]$count)
})
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
sp = jitter(as.numeric(InsectSprays$spray))
plot(sp, InsectSprays$count, main="count~spray", las=2, type="p", xaxt="n", xlab="spray", ylab="count")
suppressWarnings(arrows(sp, InsectSprays$count, sp, rep(y_i,each=12), col=adjustcolor(4, alpha.f=0.5), length=0.05))
points(y_i, pch=5, col=2)
suppressWarnings(arrows(1:6, mean(y_i), 1:6, y_i, col=adjustcolor(2, alpha.f=0.9), length=0.05))
abline(h=mean(y_i), lty=2)

axis(1, 1:length(levels(InsectSprays$spray)), labels=levels(InsectSprays$spray))
legend("top", c("Y_ij", "SC_F", "SC_res"), pch=c(1,5,5), col=c(1,2,4))
```


Pour comparer ces quantités, R. A. Fisher, après les avoir
"corrigées" par leurs degrés de liberté (ddl), a considéré leur rapport.

Nous appelons *carré moyen associé au facteur* le terme 

$$CM_F = \frac{SC_F}{|J|-1}$$

et *carré moyen résiduel* le terme :

$$CM_{res} = \frac{SC_{res}}{n-|J|}$$

Le carré moyen résiduel est un estimateur sans biais de la variance des erreurs  $\sigma^2$.
C’est pourquoi il est souvent également appelé variance résiduelle et presque systématiquement noté $S_{res}^2$ lorsqu’il sert à estimer la variance des erreurs.
Sa valeur observée sur l’échantillon est ainsi notée $cm_{res}$ ou $s_{res}^2$ .

Définissons la statistique de test :

$$ F_{obs} = \frac{cm_F}{cm_{res}}$$

Si les conditions d’aplications sont satisfaites et sous $H_0$ alors $F_{obs}$ est une réalisation d’une variable aléatoire $F$ qui suit une loi de Fisher à $|J|-1$ degrés de liberté au numérateur et $n-|J|$ degrés de liberté au dénominateur. Cette loi est notée  $\mathcal{F}_{|J|-1,n-|J|}$.

Ces informations sont résumées dans ce que le tableau de l’analyse de la variance : 

| Source de variation   | sc        | ddl  |  cm  | $F_{obs}$
| :-------------------- | :-------: | :--: | :--: | ---:
| Due au facteur        | $sc_{F}$  | $|J|-1$  | $cm_{F}=\frac{sc_{F}}{|J|-1}$ | $\frac{cm_{F}}{cm_{res}}$
| Résiduelle            | $sc_{res}$| $n-|J|$  | $cm_{res}=\frac{sc_{res}}{n-|J|}$ 
| Totale                | $sc_{tot}$| $n-1$ 


```{r echo=TRUE, results="verbatim"}
m = lm(InsectSprays$count~InsectSprays$spray)
anova(m)
```

```{r}
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
i = seq(0,40, length.out=1000)
plot(i,df(i, 5, 66), type="l", main="F_5_66")
abline(v=34.702, col=2)
```






































## Travaux pratiques


**faraway::coagulation**

  - Mettre en place une analyse de variance pour étudier l’e􏰒ffet du régime sur les temps de coagulation.
  - Analyse graphique des donnée
  - Vérifier les hypothèses du test
  

```{r echo=TRUE, results="verbatim"}
coagulation = faraway::coagulation
head(coagulation)
dim(coagulation)
table(coagulation$diet)

# Graphicals
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
plot(coagulation$diet, coagulation$coag, main="coag~diet", xlab="diet", ylab="coag", border="grey")
points(jitter(as.numeric(coagulation$diet)), coagulation$coag)
```

```{r eval=FALSE}
# Test hypothesis
m = lm(coag~diet, coagulation)
m2 = aov(coag~diet, coagulation)


## normality
m$residuals
m2$residuals
m$residuals == m2$residuals
shapiro.test(m$residuals)
# H_0 normality
# H_1 not normality
# pval = 0.86 > 0.05, we keep H_0, residuals are normal

## homoscedasticity
bartlett.test(coag~diet, coagulation)
# H_0 homoscedasticity
# H_1 not homoscedasticity
# pval = 0.6441 > 0.05, we keep H_0, variance of groups are equal

anova(m)

## ANOVA
# H_0 means of each group are equals
# H_1 means of each group  are not equals
# alpha = 5%
# pval = 4.6e-05 < 5% we reject H_0 and accept H_1 at threshold of 5%, means are not equals.


sc_F = 228
sc_res = 112

mc_F = sc_F/3
mc_F
mc_res = sc_res/20
mc_res

F_obs = mc_F/mc_res
F_obs

1 - pf(13.571, 3, 20)

layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
i = seq(0,40, length.out=1000)
plot(i,df(i, 3, 20), type="l", main="F_3_20")
abline(v=F_obs, col=2)


m = lm(coag~diet, coagulation[coagulation$diet %in% c("A", "B"),])
summary(m)
anova(lm(coag~diet, coagulation[coagulation$diet %in% c("A", "B"),]))

  

anova(lm(coag~diet, coagulation[coagulation$diet %in% c("C", "B"),]))
t.test(coagulation[coagulation$diet == "A",]$coag, coagulation[coagulation$diet == "B",]$coag)
t.test(coagulation[coagulation$diet == "B",]$coag, coagulation[coagulation$diet == "C",]$coag)
t.test(coagulation[coagulation$diet == "B",]$coag, coagulation[coagulation$diet == "B",]$coag)
t.test(coagulation[coagulation$diet == "A",]$coag, coagulation[coagulation$diet == "D",]$coag)
t.test(coagulation[coagulation$diet == "B",]$coag, coagulation[coagulation$diet == "B",]$coag)
t.test(coagulation[coagulation$diet == "B",]$coag, coagulation[coagulation$diet == "B",]$coag)

plot(TukeyHSD(m2, conf.level=0.95))
pairwise.t.test(coagulation$coag, coagulation$diet) 


pairwise.t.test(coagulation$coag, coagulation$diet, p.adjust.method="none") 
pairwise.t.test(coagulation$coag, coagulation$diet, p.adjust.method="bon") 

```


**Comparaisons multiples**


Lorsque que nous rejettons $H_0$, nous pouvons chercher à analyser les différences entre les groupes. Nous procédons alors à des tests qui vont répondre à la question suivante : D’où vient la différence ? Quelles moyennes sont différentes ?

Ces tests qui vont répondre à cette question sont les tests de comparaisons multiples, des adaptations du test de Student.

La plus connues est la correction de *Bonferroni*. Cela consiste à diviser le seuil par le nombre de comparaisons. Bonferroni a montré que cette procédure garantit un taux d’erreur global plus faible que le seuil initial.  

Dans notre exemple, nous avons décidé que les moyennes théoriques sont différentes dans leur ensemble, mais nous aurions très bien pu trouver le contraire.
Comme nous avons décidé que les moyennes théoriques sont différentes dans leur ensemble que le facteur étudié est à effets fixes et qu’il a plus de trois modalités, nous pourrions essayer de déterminer là où résident les différences avec un des tests de comparaisons multiples.





**TO DO** 

Intégrer ici les exercices de la fiche TP6.pdf











```{r, eval=FALSE}
recovery = multcomp::recovery
head(recovery)
dim(recovery)
plot(minutes~blanket, recovery)

anorexia = MASS::anorexia
head(anorexia)
dim(anorexia)


multcomp::cholesterol

```

---





























