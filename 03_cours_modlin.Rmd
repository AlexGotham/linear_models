# ANOVA à un facteur

Dans le cadre de l’analyse de la variance (**ANOVA**) on cherche une relation entre la variable observée $Y$ quantitative et la variable explicative $X$ qualitative, appellée aussi facteur. 

$$Y \sim X$$

Comme pour la regression linéaire, l’ANOVA est à la fois :

  * un **modèle** (linéaire) fondé sur la décomposition de la variance 
  * un **test** statistique permettant de comparer les moyennes d’une variable aléatoire *indépendante*, *gaussienne* et *homogène en variance*.

Ex : le poids moyen de différents groupes d’individus.

L’analyse de la variance est un outil statistique largement utilisé  en analyse de données.
  

## Présentation du modèle


Y est la variable aléatoire expliquée (modélisée) par  la variables explicatives $X$. 

Le modèle s’écrit :

$$Y = \mu + I_X \beta + \epsilon$$

avec : 

  - $Y$ un vecteur de taille $n$ (le nombre d’observations) correspondant aux valeurs de la variable aléatoire 
  - $\mu$ la moyenne des observations.  
  - $I_X \beta$ un vecteur correspondant à l’effet du groupe au quel appartient chaque observation
  - $\epsilon$ un vecteur de taille $n$ correspondant aux valeurs des résidus. 

On note : 
  
  - $\beta$ un vecteur de  $p$ (le nombre de niveaux du facteur X) correspondant à la moyenne des observation pour chaque niveau du facteur moins la moyenne générale.
  - $I_X$ la *matrice d’incidence* (tableau disjonctif ?) de taille $n$ x $p$, ne comportant que des 0 et des 1 et permettant d’associer chaque observation à son niveau de facteur $X$.   

**Exemple *InsectSprays* **

Les données *InsectSprays* décrivent 72 parcelles agricoles par le nombre d’insectes qu’elles contiennent (variable à expliquer, *count*) et le type d’insecticide auquel elles ont été exposées (variable explicative, *spray*).

On pourra tenter d’expliquer le nombre d’insectes (Y) en fonction du type de insecticide (X), ou s’intérroger sur l’effet du type de insecticide utilisé (X) sur le nombre d’insectes observé (Y).

Nous allons ici sous-échantilloner ce jeu de données pour réduire sa puissance statistique.

```{r results="verbatim", echo=TRUE}
data("InsectSprays")
InsectSprays_sub = InsectSprays[c(1:3, 13:15, 25:27, 37:39, 49:51, 61:63),]
d = InsectSprays_sub
head(d)
dim(d)
table(d$spray)
```




```{r}
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
p = plot(d$spray, d$count, main="count~spray", xlab="spray", ylab="count", border="grey")
points(jitter(as.numeric(d$spray)), d$count)


y_i = sapply(levels(d$spray), function(s) {
 mean(d[d$spray==s,]$count)
})
sp = jitter(as.numeric(d$spray))
plot(sp, d$count, main="count~spray", las=2, type="p", xaxt="n", xlab="spray", ylab="count")
suppressWarnings(arrows(sp, d$count, sp, rep(y_i, each=table(d$spray)[1]), col=adjustcolor(4, alpha.f=0.5), length=0.05))
points(y_i, pch=5, col=2)
suppressWarnings(arrows(1:6, mean(y_i), 1:6, y_i, col=adjustcolor(2, alpha.f=0.9), length=0.05))
abline(h=mean(y_i), lty=2)

axis(1, 1:length(levels(d$spray)), labels=levels(d$spray))
legend("top", c("Y_i", "beta_i", "epsilon_i", "mu"), pch=c(1,5,5,NA), col=c(1,2,4,1), lty=c(0,0,0,2), border=0)
```






---

## Estimation des paramètres


Le modèle $Y = \mu + I_X \beta + \epsilon$ devient pour chaque observation $i \in \{1, ..., n\}$ :

$$Y_i = \mu + \beta_i + \epsilon_i$$

avec $\beta_i$ l’effet du groupe auquel appartient la *i*-ème observation.

Dans le cas d’un plan **équi-distribué** : 

  - l’effet d’un groupe se calcul comme la différence entre la moyenne des observations du groupe et la moyenne de toutes les observations.
  - la somme des effets des groupes est nulle.

Dans notre exemple $\beta_i$ prend ses valeurs dans $\{ \beta_A, \beta_B, \beta_C, \beta_D, \beta_E, \beta_F \}$, les moyennes des observations pour les individus des groupes A, B, C, D, E et F. Les groupes sont équilibrés donc $\beta_A + \beta_B + \beta_C + \beta_D + \beta_E + \beta_F = \mu$ 




























---

## Qualité du modèle

### Décomposition de la variance

**Notations**

Plaçons nous dans le cas d’un plan **équi-distribué**. Les observations sont notées $Y_{jk}$ avec :

- $j$ identifie les niveaux du facteur $X$ (dans notre exemple, le type d’insecticide, $j \in J = \{ A, B, C, D, E, F \}$).
- $k$ identifie la *k*-éme observation pour un niveau de facteur donné (dans notre exemple, pour chaque type d’insecticide, $k \in K = \{1,...,3\}$).

Les observations d’un niveau de facteur donné sont appelés des **réplicats**. D’une maniére générale, les réplicats correspondnent à la répétition de la mesure Y pour des conditions expérimentales similaires.

Les groupes sont de même taille, nous disons que l’expérience est équilibrée. 
Au delà du fait que cela simplifie la notation, cela confère de bonnes propriétés utilisées pour décomposer la variance.

La moyenne observée du groupe $j$ s’écrit : 
$$\overline Y_j = \frac{1}{|K|}\sum_{k \in K}Y_{jk}$$

La variance observée du groupe $j$ s’écrit : 
$$s_j^2(Y) = \frac{1}{|K|}\sum_{k \in K}(Y_{jk} -\overline Y_j)^2$$


*Remarque* : Cette dernière formule exprime la variance non corrigée. Très souvent, dans les ouvrages ou les logiciels, c’est la variance corrigée qui est utilisée : au lieu d’être divisée par $|K|$, la somme est divisée par $|K| − 1$.


**Propriétés fondamentales**

La décomposition est fondée sur deux propriétés des moyennes et des variances.

(1) La moyenne de toutes les observations est la moyenne des moyennes de chaque échantillon : 

$$\overline{Y} 
  = \frac{1}{n} \sum_{j \in J} \sum_{k\in K} Y_{jk}
  = \frac{1}{|J| . |K|} \sum_{j \in J} \sum_{k\in K} Y_{jk}
  = \frac{1}{|J|} \sum_{j \in J} \frac{1}{|K|} \sum_{k\in K} Y_{jk}
  = \frac{1}{|J|} \sum_{j \in J} \overline{Y_j} $$


(2) La variance de toutes les observations est la somme de la variance des moyennes de chaque groupe et des variances de chaque observation autour de la moyenne de son groupe :

$$s^2(Y) 
  = \frac{1}{n} \sum_{j \in J} \sum_{k \in K} (Y_{jk} - \overline{Y})^2 
  = \frac{1}{n} \sum_{j \in J} \sum_{k \in K} (Y_{jk} - \overline Y_j)^2 + (\overline Y_j - \overline{Y})^2 
  = \frac{1}{|J|} \sum_{j \in J} (\overline{Y_j} - \overline{Y})^2 + \frac{1}{|J|} \sum_{j \in J} s_j^2(Y) $$



---

### $R^2$

On conserve la proriété vu dans la regression linéaire :
 
$$ SC_{tot} = SC_{F} + SC_{res}$$ 

Avec $SC_{tot}$ la somme des carrés totale,  $SC_{F}$ la somme des carrés des facteurs et  $SC_{res}$ la somme des carrés des résidus.


Le coefficient de determination $R^2$ mesure du pourcentage de la variance expliquée par le modèle :

$$ R^2 = \frac{SC_{F}}{SC_{tot}}$$


```{r}
d = InsectSprays_sub

y_i = sapply(levels(d$spray), function(s) {
 mean(d[d$spray==s,]$count)
})
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
sp = jitter(as.numeric(d$spray))
plot(sp, d$count, main="count~spray", las=2, type="p", xaxt="n", xlab="spray", ylab="count")
suppressWarnings(arrows(sp, d$count, sp, rep(y_i, each=table(d$spray)[1]), col=adjustcolor(4, alpha.f=0.5), length=0.05))
points(y_i, pch=5, col=2)
suppressWarnings(arrows(1:6, mean(y_i), 1:6, y_i, col=adjustcolor(2, alpha.f=0.9), length=0.05))
abline(h=mean(y_i), lty=2)

axis(1, 1:length(levels(d$spray)), labels=levels(d$spray))
legend("top", c("Y_ij", "SC_F", "SC_res"), pch=c(1,5,5), col=c(1,2,4))
```






**Travaux pratiques**

  - Reprendre le travail effectué sur le jeu de données *CO2*.
  - Considérer la concentration en CO2 comme un facteur
  - Evaluer la part de variance expliquée par ce nouveau modèle (R^2)
  - Commenter


```{r echo=TRUE, results="verbatim"}
data(CO2)
d = CO2[CO2$Type=="Quebec" & CO2$Treatment=="chilled", ]
head(CO2)
d$conc_log = log(d$conc)
d$conc_fact = as.factor(d$conc)
m1 = lm(uptake~conc, d)
m2 = lm(uptake~conc_log, d)
layout(matrix(1:3, 1), respect=TRUE)
plot(
  d$conc, 
  d$uptake, 
  xlab="conct", ylab="uptake", main=paste0("uptake~conc R^2=", signif(summary(m1)$r.squared,3))
)
abline(m1, col=2)
plot(
  d$conc_log, 
  d$uptake, 
  xlab="conc_log", ylab="uptake", main=paste0("uptake~conc_log R^2=", signif(summary(m2)$r.squared,3))
)
abline(m2, col=2)
plot(
  d$conc_fact, 
  d$uptake, 
  xlab="log(conc_fact)", ylab="uptake", main=paste0("uptake~conc_fact")
)
```


```{r eval=FALSE}
# README RStudio config, uncheck: # preferences > R Markdown > show output inline for... 
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
plot(
  d$conc, 
  d$uptake, 
  xlab="conc_fact", ylab="uptake", main=paste0("uptake~conc_fact R^2=", signif(summary(m1)$r.squared,3))
)
m = lm(uptake ~ conc, d)
abline(a=m$coefficients[[1]], b=m$coefficients[[2]], col=2) # /!\ y = b.x + a
arrows(d$conc, d$uptake, d$conc, d$uptake-m$residuals, col=adjustcolor(4, alpha.f=0.5), length=0.1)
legend("bottomright",c("regression line", "residuals"), col=c(2,4), lty=1, cex=.8)

m2 = lm(uptake ~ conc_fact, d)
summary(m2)$r.squared
p = plot(d$conc_fact, d$uptake, las=2, main=paste0("uptake~conc_fact R^2=", signif(summary(m2)$r.squared,3)))
conc_fact = jitter(as.numeric(d$conc_fact))
arrows(conc_fact, d$uptake, conc_fact, d$uptake-m2$residuals, col=adjustcolor(4, alpha.f=0.5), length=0.1)
legend("bottomright","residuals", col=4, lty=1, cex=.8)
```
  
---




























## Tests statistiques


### Test de   Fisher

Le test de l’ANOVA à 1 facteur (*one way ANOVA*), s’applique sous certaines conditions : 

- Indépendance des observations
- Homoscedasticité entre les groupes
- Normalité des résidus,

l’ANOVA est un test de comparaison des moyennes des facteurs : 

- hypothèse nulle $H_0, \mu_1 =\mu_2 =···=\mu_I$
- hypothèse alternative $H_1, \text{les moyennes } \mu_i \text{ ne sont pas toutes égales.}$

**Intuition du test** Si l’hypothèse nulle $H_0$ est vraie alors la quantité $SC_F$ (rouge) doit être petite par rapport à la quantité $SC_{res}$ (bleu).
Par contre, si l’hypothèse alternative $H_1$ est vraie alors la quantité $SC_F$ doit être grande par rapport à la quantité $SC_{res}$.


```{r}
d = InsectSprays_sub

y_i = sapply(levels(d$spray), function(s) {
 mean(d[d$spray==s,]$count)
})
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
sp = jitter(as.numeric(d$spray))
plot(sp, d$count, main="count~spray", las=2, type="p", xaxt="n", xlab="spray", ylab="count")
suppressWarnings(arrows(sp, d$count, sp, rep(y_i, each=table(d$spray)[1]), col=adjustcolor(4, alpha.f=0.5), length=0.05))
points(y_i, pch=5, col=2)
suppressWarnings(arrows(1:6, mean(y_i), 1:6, y_i, col=adjustcolor(2, alpha.f=0.9), length=0.05))
abline(h=mean(y_i), lty=2)

axis(1, 1:length(levels(d$spray)), labels=levels(d$spray))
legend("top", c("Y_ij", "SC_F", "SC_res"), pch=c(1,5,5), col=c(1,2,4))
```


Pour comparer ces quantités, R. A. Fisher, après les avoir
"corrigées" par leurs degrés de liberté (ddl), a considéré leur rapport.

Nous appelons *carré moyen associé au facteur* le terme 

$$CM_F = \frac{SC_F}{|J|-1}$$

et *carré moyen résiduel* le terme :

$$CM_{res} = \frac{SC_{res}}{n-|J|}$$

Le carré moyen résiduel est un estimateur sans biais de la variance des erreurs  $\sigma^2$.
C’est pourquoi il est souvent également appelé variance résiduelle et presque systématiquement noté $S_{res}^2$ lorsqu’il sert à estimer la variance des erreurs.
Sa valeur observée sur l’échantillon est ainsi notée $CM_{res}$ ou $s_{res}^2$ .

Définissons la statistique de test :

$$ F_{obs} = \frac{CM_F}{CM_{res}}$$

Si les conditions d’aplications sont satisfaites et sous $H_0$ alors $F_{obs}$ est une réalisation d’une variable aléatoire $F$ qui suit une loi de Fisher à $|J|-1$ degrés de liberté au numérateur et $n-|J|$ degrés de liberté au dénominateur. Cette loi est notée  $\mathcal{F}_{|J|-1,n-|J|}$.

Ces informations sont résumées dans ce que le tableau de l’analyse de la variance : 

| Source de variation   | SC        | ddl  |  CM  | $F_{obs}$
| :-------------------- | :-------: | :--: | :--: | ---:
| Due au facteur        | $SC_{F}$  | $|J|-1$  | $CM_{F}  =\frac{SC_{F}}{|J|-1}$ | $\frac{CM_{F}}{CM_{res}}$
| Résiduelle            | $SC_{res}$| $n-|J|$  | $CM_{res}=\frac{SC_{res}}{n-|J|}$ 
| Totale                | $SC_{tot}$| $n-1$ 


```{r echo=TRUE, results="verbatim"}
d = InsectSprays_sub
m = lm(count~spray,d)
anova(m)
```

```{r}
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
p = plot(d$spray, d$count, main="count~spray", xlab="spray", ylab="count", border="grey")
points(jitter(as.numeric(d$spray)), d$count)



x=seq(0,15, length.out=200)
plot(x, df(x, anova(m)[1,1], anova(m)[2,1]), type="l", xlab="F", ylab="", main=paste0("Distibution de Fisher,  ", anova(m)[1,1]," et ", anova(m)[2,1]," ddl."))
abline(v=anova(m)[1,4], lty=2, col=4)
abline(v=qf(0.95, anova(m)[1,1], anova(m)[2,1]), lty=2, col=2)
x = seq(15,qf(0.95, anova(m)[1,1], anova(m)[2,1]), length.out=100)
polygon(c(15, x, qf(0.95, anova(m)[1,1], anova(m)[2,1])), c(0, df(x, anova(m)[1,1], anova(m)[2,1]), 0), col=adjustcolor(2, alpha.f=.5), border=2, lwd=3)
x = seq(15,anova(m)[1,4], length.out=100)
polygon(c(15, x, anova(m)[1,4]), c(0, df(x, anova(m)[1,1], anova(m)[2,1]), 0), col=adjustcolor(4, alpha.f=.5), border=4, lwd=3)
legend("topright",c("F_obs", "c_alpha", "p-value", "5%"), col=c(4,2, 4, 2), lty=c(2,2,1,1), lwd=c(1,1,3,3), cex=.8)
```







*Remarque* : on peut aussi écrire ce test à l’qide d’une table disjonctif : 

```{r echo=TRUE, results="verbatim"}
d$A = 0
d$B = 0
d$C = 0
d$D = 0
d$E = 0
d$F = 0
for (i in 1:nrow(d)) {
  d[i,as.character(d[i,"spray"])] = 1
}
d
m0 = lm(count~A+B+C+D+E+F,d)
summary(m0)
m00 = lm(count~A+B+C+D+E,d)
summary(m00)
```






### Test de Tuckey

Lorsque que nous rejettons $H_0$, nous pouvons chercher à analyser les différences entre les groupes. 
Nous procédons alors à des tests qui vont répondre aux questions suivantes : 

  - D’où vient la différence ? 
  - Quelles moyennes sont différentes ?
  

Ces tests qui vont répondre à cette question sont les tests de comparaisons multiples, des adaptations du test de Student.


En pratique, pour répondre à ces questions on utilise le test de **Tuckey**.
  
```{r echo=TRUE, results="verbatim"}
layout(matrix(1:2,1), respect=TRUE)

d = InsectSprays_sub
m = aov(count~spray,d)
plot(TukeyHSD(m, conf.level=0.95), las=2)

d = InsectSprays
m = aov(count~spray,d)
plot(TukeyHSD(m, conf.level=0.95), las=2)


layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
p = plot(d$spray, d$count, main="count~spray", xlab="spray", ylab="count", border="grey")
points(jitter(as.numeric(d$spray)), d$count)
```

On peut aussi réaliser plusieurs Test de Student et appliqué une correction

La plus connues est la correction de **Bonferroni**. Cela consiste à diviser le seuil par le nombre de comparaisons. 
Bonferroni a montré que cette procédure garantit un taux d’erreur global plus faible que le seuil initial (conservatif).  


```{r echo=TRUE, results="verbatim"}
d = InsectSprays_sub
pairwise.t.test(d$count, d$spray, p.adjust.method="none") 
pairwise.t.test(d$count, d$spray, p.adjust.method="bon") 
```


Une autre méthode utilisée quand le nombre de tests multiples à réalisé est très grand est la procédure de contrôle du taux de fausses découverte (FDR) de **Benjamini-Hochberg** [Y. Benjamini, Y. Hochberg. *Controlling the false discovery rate : a practical and powerful approach to multiple testing*. Journal of the Royal Statistical Society, Series B (Methodological), 1995, p289-300.].








































## Exercices


**faraway::coagulation**

Etudier le modèle le modèle $coag \sim diet$ : 


1. Ecriture analytique du modèle ;
2. Formulation des hypothèses $\mathcal{H}_0$ et $\mathcal{H}_1$ ;
3. Statistique de test utilisée et conditions d’application ; 
4. Valeur de la statistique de test ; 
5. P-valeur associée ; 
6. Conclusion du test ; 
7. Tests de comparaisons multiples à l’aide de la méthode de votre choix.


```{r echo=TRUE, results="verbatim"}
d = faraway::coagulation
head(d)
dim(d)
table(d$diet)

# Graphicals
layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
plot(d$diet, d$coag, main="coag~diet", xlab="diet", ylab="coag", border="grey")
points(jitter(as.numeric(d$diet)), d$coag)
```

```{r eval=FALSE}
d = faraway::coagulation
# Test hypothesis
m = lm(coag~diet, d)


## normality
m$residuals
shapiro.test(m$residuals)
# H_0 normality
# H_1 not normality
# pval = 0.86 > 0.05, we keep H_0, residuals are normal

## homoscedasticity
bartlett.test(coag~diet, d)
# H_0 homoscedasticity
# H_1 not homoscedasticity
# pval = 0.6441 > 0.05, we keep H_0, variance of groups are equal

anova(m)

## ANOVA
# H_0 means of each group are equals
# H_1 means of each group  are not equals
# alpha = 5%
# pval = 4.6e-05 < 5% we reject H_0 and accept H_1 at threshold of 5%, means are not equals.

layout(matrix(1:2, 1, byrow=TRUE), respect=TRUE)
plot(d$diet, d$coag, main="coag~diet", xlab="diet", ylab="coag", border="grey")
points(jitter(as.numeric(d$diet)), d$coag)
plot(TukeyHSD(aov(coag~diet, d), conf.level=0.95))

pairwise.t.test(d$coag, d$diet, p.adjust.method="none") 
pairwise.t.test(d$coag, d$diet, p.adjust.method="bon") 
pairwise.t.test(d$coag, d$diet, p.adjust.method="BH") 

pairwise.t.test(d$coag, d$diet, p.adjust.method="none", pool.sd=FALSE) 

anova(lm(coag~diet, d[d$diet %in% c("C", "B"),]))
t.test(d[d$diet == "A",]$coag, d[d$diet == "B",]$coag)
t.test(d[d$diet == "B",]$coag, d[d$diet == "C",]$coag)
t.test(d[d$diet == "B",]$coag, d[d$diet == "B",]$coag)
t.test(d[d$diet == "A",]$coag, d[d$diet == "D",]$coag)
t.test(d[d$diet == "B",]$coag, d[d$diet == "B",]$coag)
t.test(d[d$diet == "B",]$coag, d[d$diet == "B",]$coag)

```






**Autres jeux de données** 

```{r echo=TRUE, results="verbatim"}
d = multcomp::recovery
head(d)
dim(d)
table(d$blanket)
layout(1, respect=TRUE)
plot(minutes~blanket, d)

d = multcomp::cholesterol
head(d)
dim(d)
table(d$trt)
layout(1, respect=TRUE)
plot(response~trt, d)

d = MASS::anorexia
head(d)
dim(d)
table(d$Treat)
d$delta = d$Postwt - d$Prewt 
layout(matrix(1:2,1), respect=TRUE)
plot(d$Postwt, d$Prewt)
plot(delta~Treat, d)

d = ISwR::lung
head(d)
dim(d)
table(d$method, d$subject)
layout(matrix(1:2,1), respect=TRUE)
plot(volume~method+subject, d)

library(lsmeans)
d = auto.noise
head(d)
dim(d)
table(d$size, d$type)
layout(matrix(1:2,1), respect=TRUE)
plot(noise~size+type, d)

d = faraway::rats
head(d)
dim(d)
table(d$poison, d$treat)
layout(matrix(1:2,1), respect=TRUE)
plot(time~poison+treat, d)


```




